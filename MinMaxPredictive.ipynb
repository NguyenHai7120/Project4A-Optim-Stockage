{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIN MAX PREDICTIVE METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will implement the min max predictive method. Since we aim to a lossless compresion, so we need to be able to decode the compressed images. Here we propose an another method than the original method is the paper but we borrow the main ideas.\n",
    "\n",
    "We suppose that we have a set of `N` very similar images and let `I_min` and `I_max` be the minimum image and the maximum image. \\\n",
    "The main idea is that, instead of storing the original pixel values, we will make a predictive scheme and store the difference between the predicted pixel values and the original pixel values.\n",
    "\n",
    "For each pixel $p$ of image $I$, we denote $L_p = \\lfloor m.\\frac{I_p - I_\\text{min.p}}{I_\\text{max.p} - I_\\text{min.p}} \\rfloor$ the level of that pixel, and where $m$ is the number of possible levels that we can consider as a hyper parameter of our method. \n",
    "\n",
    "Hence, the predicted value is computed as $\\hat{I_p} = I_\\text{min.p} + \\frac{L_p}{m}(I_\\text{max.p} - I_\\text{min.p})$, then we store the distance $I_p - \\hat{I_p}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.measure as skm\n",
    "from Outils.dataloader import load_CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\n",
      "Training labels shape:  (50000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the raw CIFAR-10 data.\n",
    "cifar10_dir = 'Dataset/cifar-10-batches-py'\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_encoder(I, Imin, Imax, m = 20, block_size = (2,2,1)):\n",
    "    '''\n",
    "    Image encoder of min max predictive method\n",
    "    Input:  I - image of shape (H, W, 3)\n",
    "\n",
    "    Return: encoded_image : numpy array of the same shape as channel\n",
    "            level_image : numpy array of shape image.shape / block_size (by each dim)\n",
    "    '''\n",
    "    encoded_image = np.zeros(I.shape)\n",
    "    level_image = m*(I - Imin)/(Imax - Imin)\n",
    "    level_image = level_image.astype(int)\n",
    "    level_image = skm.block_reduce(level_image, block_size = block_size, func = np.min)\n",
    "    I_hat = Imin + np.floor(np.kron(level_image, np.ones(block_size))*(Imax - Imin)/m)\n",
    "    encoded_image = I - I_hat\n",
    "\n",
    "    return encoded_image, level_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_decoder(I_encoded, level, Imin, Imax, m = 20, block_size = (2,2,1)):\n",
    "    I_hat = Imin + np.floor(np.kron(level, np.ones(block_size))*(Imax - Imin)/m)\n",
    "    return I_encoded + I_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imin = np.min(X_train[:10], axis=0)\n",
    "Imax = np.max(X_train[:10], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = X_train[0]\n",
    "I_encoded, I_level = image_encoder(I, Imin, Imax)\n",
    "I_decoded = image_decoder(I_encoded, I_level, Imin, Imax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(I != I_decoded)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ccd7312afbc7f6b085d2146f709040387adf44f7120b2b3d2b8d45900fc5481"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
